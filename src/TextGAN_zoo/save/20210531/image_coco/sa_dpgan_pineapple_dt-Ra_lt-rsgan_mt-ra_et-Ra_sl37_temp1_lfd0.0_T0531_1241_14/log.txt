====================================================================================================
> training arguments:
>>> if_test: 0
>>> run_model: sa_dpgan
>>> k_label: 2
>>> dataset: image_coco
>>> model_type: pineapple
>>> loss_type: rsgan
>>> mu_type: ragan
>>> eval_type: Ra
>>> d_type: Ra
>>> if_real_data: 1
>>> sa: 1
>>> cuda: 1
>>> device: 0
>>> devices: 0
>>> shuffle: 0
>>> gen_init: normal
>>> dis_init: uniform
>>> n_parent: 1
>>> eval_b_num: 8
>>> lambda_fq: 1.0
>>> lambda_fd: 0.0
>>> d_out_mean: True
>>> freeze_dis: False
>>> freeze_clas: False
>>> use_all_real_fake: False
>>> use_population: False
>>> samples_num: 1000
>>> vocab_size: 4658
>>> mle_epoch: 120
>>> clas_pre_epoch: 10
>>> adv_epoch: 200
>>> inter_epoch: 15
>>> batch_size: 64
>>> max_seq_len: 37
>>> start_letter: 1
>>> padding_idx: 0
>>> gen_lr: 0.01
>>> gen_adv_lr: 0.2
>>> dis_lr: 0.01
>>> clip_norm: 5.0
>>> pre_log_step: 10
>>> adv_log_step: 1
>>> train_data: dataset/image_coco.txt
>>> test_data: dataset/testdata/image_coco_test.txt
>>> temp_adpt: exp
>>> evo_temp_step: 1
>>> temperature: 1
>>> ora_pretrain: 0
>>> gen_pretrain: 0
>>> dis_pretrain: 0
>>> adv_g_step: 1
>>> rollout_num: 16
>>> gen_embed_dim: 32
>>> gen_hidden_dim: 32
>>> goal_size: 16
>>> step_size: 4
>>> mem_slots: 1
>>> num_heads: 4
>>> head_size: 64
>>> gen_nlayers: 2
>>> gen_num_heads: 4
>>> dropout: 0.5
>>> d_step: 5
>>> d_epoch: 3
>>> adv_d_step: 4
>>> adv_d_epoch: 2
>>> dis_embed_dim: 64
>>> dis_hidden_dim: 64
>>> num_rep: 64
>>> dis_nlayers: 2
>>> dis_num_heads: 4
>>> use_nll_oracle: 1
>>> use_nll_gen: 1
>>> use_nll_div: 1
>>> use_bleu: 1
>>> use_self_bleu: 0
>>> use_clas_acc: True
>>> use_ppl: 0
>>> log_file: log/log_0531_1241_14.txt
>>> save_root: save/20210531/image_coco/sa_dpgan_pineapple_dt-Ra_lt-rsgan_mt-ra_et-Ra_sl37_temp1_lfd0.0_T0531_1241_14/
>>> signal_file: run_signal.txt
>>> tips: SA_DPGAN experiments
====================================================================================================
Loading image_coco dataset
Starting Generator MLE Training...
[MLE-GEN] epoch 0 : Epoch = 0, pre_loss = 2.1918, BLEU-[2, 3, 4, 5] = [0.406, 0.098, 0.042, 0.025], NLL_gen = 1.6169, NLL_div = 5.2266, Self-BLEU-[2, 3, 4] = 0, [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 10 : Epoch = 10, pre_loss = 1.2352, BLEU-[2, 3, 4, 5] = [0.345, 0.078, 0.034, 0.021], NLL_gen = 1.24, NLL_div = 6.8568, Self-BLEU-[2, 3, 4] = 0, [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 20 : Epoch = 20, pre_loss = 1.1771, BLEU-[2, 3, 4, 5] = [0.326, 0.074, 0.033, 0.021], NLL_gen = 1.1936, NLL_div = 6.9322, Self-BLEU-[2, 3, 4] = 0, [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 30 : Epoch = 30, pre_loss = 1.1540, BLEU-[2, 3, 4, 5] = [0.347, 0.078, 0.034, 0.021], NLL_gen = 1.1778, NLL_div = 7.2718, Self-BLEU-[2, 3, 4] = 0, [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 40 : Epoch = 40, pre_loss = 1.1337, BLEU-[2, 3, 4, 5] = [0.332, 0.074, 0.033, 0.021], NLL_gen = 1.1529, NLL_div = 7.2254, Self-BLEU-[2, 3, 4] = 0, [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 50 : Epoch = 50, pre_loss = 1.1190, BLEU-[2, 3, 4, 5] = [0.347, 0.078, 0.035, 0.022], NLL_gen = 1.145, NLL_div = 7.5771, Self-BLEU-[2, 3, 4] = 0, [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 60 : Epoch = 60, pre_loss = 1.1100, BLEU-[2, 3, 4, 5] = [0.348, 0.078, 0.035, 0.022], NLL_gen = 1.1283, NLL_div = 7.7059, Self-BLEU-[2, 3, 4] = 0, [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 70 : Epoch = 70, pre_loss = 1.1033, BLEU-[2, 3, 4, 5] = [0.35, 0.078, 0.036, 0.023], NLL_gen = 1.1189, NLL_div = 7.7428, Self-BLEU-[2, 3, 4] = 0, [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 80 : Epoch = 80, pre_loss = 1.0950, BLEU-[2, 3, 4, 5] = [0.349, 0.08, 0.036, 0.022], NLL_gen = 1.118, NLL_div = 7.4824, Self-BLEU-[2, 3, 4] = 0, [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 90 : Epoch = 90, pre_loss = 1.0891, BLEU-[2, 3, 4, 5] = [0.357, 0.081, 0.038, 0.025], NLL_gen = 1.1076, NLL_div = 7.4007, Self-BLEU-[2, 3, 4] = 0, [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 100 : Epoch = 100, pre_loss = 1.0832, BLEU-[2, 3, 4, 5] = [0.338, 0.078, 0.036, 0.023], NLL_gen = 1.1029, NLL_div = 7.6739, Self-BLEU-[2, 3, 4] = 0, [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 110 : Epoch = 110, pre_loss = 1.0816, BLEU-[2, 3, 4, 5] = [0.346, 0.081, 0.037, 0.023], NLL_gen = 1.0974, NLL_div = 7.4222, Self-BLEU-[2, 3, 4] = 0, [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 119 : Epoch = 119, pre_loss = 1.0782, BLEU-[2, 3, 4, 5] = [0.362, 0.084, 0.039, 0.025], NLL_gen = 1.1005, NLL_div = 7.3934, Self-BLEU-[2, 3, 4] = 0, [PPL-F, PPL-R] = 0
Starting Discriminator Training...
[MLE-DIS] d_step 0: pos_reward = 2254.2739, neg_reward = 4.0617,
[MLE-DIS] d_step 1: pos_reward = 7190.1860, neg_reward = 36.4004,
[MLE-DIS] d_step 2: pos_reward = 16133.6426, neg_reward = 20.1546,
[MLE-DIS] d_step 3: pos_reward = 29799.4258, neg_reward = 4.6584,
[MLE-DIS] d_step 4: pos_reward = 45050.5703, neg_reward = 7.7504,
Starting Adversarial Training...
Initial generator: BLEU-[2, 3, 4, 5] = [0.362, 0.08, 0.037, 0.024], NLL_gen = 1.1021, NLL_div = 7.4067, Self-BLEU-[2, 3, 4] = 0, [PPL-F, PPL-R] = 0
-----
ADV EPOCH 0
-----
